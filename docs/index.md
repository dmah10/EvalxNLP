# **Welcome to EvalxNLP documentation!**

<img src="https://img.shields.io/badge/Python-3.10%2B-blue?logo=python" alt="Python">
<img src="https://img.shields.io/badge/Version-1.0.0-orange" alt="Version">

**EvalxNLP** is a Python framework for benchmarking state-of-the-art feature attribution methods for transformer-based NLP models

The framework allows users to:

- Visualize and compare Transformers-based models output explanations using various
  Ph-FA methods.

- Use natural language text explanations from LLMs to interpret importance scores and
  evaluation metrics for different explainers.

- Evaluate effectiveness of explainers using a variety of evaluation metrics for faithfulness,
  plausibility, and complexity.

## Contents

### Usage

- [Installation](usage/installation.md)
- [Explaining](usage/explaining.md)
- [Benchmarking](usage/benchmarking.md)
- [Generating LLM Explanations](usage/llm_explanations.md)
- [Advanced Features](usage/advanced_usage.md)

### Tutorials

- [Sentiment Analysis](tutorials/sentiment_analysis.md)
- [Hate Speech Detection](tutorials/hate_speech.md)

### Technical Reference

- [Explainers](reference/explainers.md)
- [Metrics](reference/metrics.md)
- [Tasks and Datasets](reference/tasks_datasets.md)
- [LLM Explanations](reference/llm_explanations.md)
---
